#!/usr/bin/env python3

"""
Randomly sample files from the Mullvad WireGuard configuration generator.

Mullvad offer a bewildering array of servers.  It is usually not practical to
load configuration for all servers into any one device.  This program samples a
small random subset from the large upstream superset.  Sampler behaviour may be
tailored to suit individual requirements.  Output from this program is intended
to be imported en masse into the WireGuard clients for Android, iOS, and macOS.

Navigate to the Mullvad WireGuard configuration file generator:

https://mullvad.net/en/account/#/wireguard-config/

Plug in your Mullvad WireGuard private key.  Select 'All countries'.  Click the
'Download zip archive' button.  Unpack the archive somewhere on your filesystem;
this directory must be specified as the src-dir argument to this script.

The following constraints apply to the WireGuard application for Android:

  * No more than 15 tunnel configurations may be loaded at a time.
    (avoid large values for -n)
  * Configuration file names are subject to a length limit.
    https://lists.zx2c4.com/pipermail/wireguard/2019-December/004772.html
    (avoid --rename)

Requires Python 3.7 or later.
"""

# pylint: disable=consider-using-f-string
# pylint: disable=invalid-name
# pylint: disable=missing-class-docstring
# pylint: disable=missing-function-docstring

import argparse
import configparser
import itertools
import logging
import os
import os.path
import random
import re
import sys
from collections import Counter
from dataclasses import dataclass, field
from functools import lru_cache, partial
from operator import attrgetter

ichain = itertools.chain.from_iterable


DEFAULT_BASENAME_PREFIX = "mlvd-"

# Higher numeric values are given preference.  Absolute values not significant.
PRIO_SHUN    = 1
PRIO_DEFAULT = 2
PRIO_PREFER  = 3


LOGGER = logging.getLogger(__name__)


class Error(Exception):
    pass


class Region(str):

    _RE = re.compile(r"(?P<region>[A-Za-z]+)", flags=re.ASCII)

    @classmethod
    def parse(cls, s):
        m = cls._RE.fullmatch(s)
        if not m:
            raise ValueError(f"invalid region: {s!r}")
        return cls(m["region"].lower())

    @classmethod
    def parse_partial(cls, s):
        m = cls._RE.match(s)
        if not m:
            raise ValueError(f"invalid region: {s!r}")
        return cls(m["region"].lower()), s[m.end(1):]


@dataclass(frozen=True)
class RegionCount:
    region: Region
    count:  int

    # prefixed with Region
    _RE = re.compile(r":(?P<count>\d+)", flags=re.ASCII)

    @classmethod
    def parse(cls, s):
        region, rest = Region.parse_partial(s)
        m = cls._RE.fullmatch(rest)
        if not m:
            raise ValueError(f"invalid region-count: {s!r}")
        return cls(region=region, count=int(m["count"]))


@dataclass(frozen=True, order=True)
class ServerID:
    region:   Region
    instance: int

    # prefixed with Region
    _RE = re.compile(r"(?P<instance>\d+)", flags=re.ASCII)

    @classmethod
    def parse(cls, s):
        region, rest = Region.parse_partial(s)
        m = cls._RE.fullmatch(rest)
        if not m:
            raise ValueError(f"invalid server ID: {s!r}")
        return cls(region=region, instance=int(m["instance"]))

    @classmethod
    def parse_partial(cls, s):
        region, rest = Region.parse_partial(s)
        m = cls._RE.match(rest)
        if not m:
            raise ValueError(f"invalid server ID: {s!r}")
        return cls(region=region, instance=int(m["instance"])), rest[m.end(1):]

    def __str__(self):
        return f"{self.region}{self._instance_zfill}"

    @property
    def _instance_zfill(self):
        return str(self.instance).zfill(3)


@dataclass(frozen=True, order=True)
class ServerIDPrioritised:
    sid:      ServerID
    priority: int = field(default=PRIO_DEFAULT, compare=False)

    def __str__(self):
        return str(self.sid)

    def __getattr__(self, name):
        return getattr(self.sid, name)


@dataclass(frozen=True, order=True)
class ServerIDName:
    sid:  ServerID
    name: str

    # prefixed with ServerID
    _RE = re.compile(r":(?P<name>[\w-]+)")

    @classmethod
    def parse(cls, s):
        sid, rest = ServerID.parse_partial(s)
        m = cls._RE.fullmatch(rest)
        if not m:
            raise ValueError(f"invalid name: {s!r}")
        return cls(sid=sid, name=m["name"])


@dataclass(frozen=True)
class Configuration:
    path: str
    sid:  ServerID

    _PREFIX     = "mullvad-"
    _PREFIX_LEN = len(_PREFIX)
    _SUFFIX     = ".conf"
    _SUFFIX_LEN = len(_SUFFIX)

    @classmethod
    def match(cls, path):
        basename = os.path.basename(path)
        if not basename.startswith(cls._PREFIX):
            return None
        if not basename.endswith(cls._SUFFIX):
            return None
        sid = ServerID.parse(basename[cls._PREFIX_LEN:-cls._SUFFIX_LEN])
        return cls(path=path, sid=sid)

    def basename(self, prefix=DEFAULT_BASENAME_PREFIX, suffix=None):
        if not suffix:
            suffix = str(self.sid)
        return f"{prefix}{suffix}.conf"

    def read(self):
        c = configparser.ConfigParser()
        c.read(self.path)
        return c


class PriorityCache:

    def __init__(self):
        self._by_region = {}
        self._by_server_id = {}

    def lookup(self, server_id):
        prios = [self._by_server_id.get(server_id),
                 self._by_region.get(server_id.region),
                 PRIO_DEFAULT]
        return next(p for p in prios if p)

    def shun_region(self, region):
        self._by_region[region] = PRIO_SHUN

    def prefer_region(self, region):
        self._by_region[region] = PRIO_PREFER

    def shun_server_id(self, server_id):
        self._by_server_id[server_id] = PRIO_SHUN

    def prefer_server_id(self, server_id):
        self._by_server_id[server_id] = PRIO_PREFER


@dataclass
class TransformTemplate:
    basename_prefix: str = ""
    private_key:     str = ""
    dns_servers:     str = ""

    def default(self):
        def transform(cfg):
            data = cfg.read()
            if self.private_key:
                dict_deep_set(data, ("Interface", "PrivateKey"), self.private_key)
            if self.dns_servers:
                dict_deep_set(data, ("Interface", "DNS"), self.dns_servers)
            return self._basename(cfg), data
        return transform

    def rename(self, new_name):
        def transform(cfg):
            inner_transform = self.default()
            _, data = inner_transform(cfg)
            return self._basename(cfg, suffix=new_name), data
        return transform

    def _basename(self, cfg, suffix=None):
        return cfg.basename(**{
            **({"prefix": self.basename_prefix} if self.basename_prefix else {}),
            **({"suffix": suffix} if suffix else {})})


TRANSFORMS = TransformTemplate()


def compose(initial, *funcs):
    v = initial
    for f in funcs:
        v = f(v)
    return v


def dict_deep_set(d, keys, value):
    *head, tail = keys
    for k in head:
        try:
            d = d[k]
        except KeyError:
            d[k] = {}
            d = d[k]
    d[tail] = value


def find_dupes(iterable):
    return [v for v, c in Counter(iterable).items() if c > 1]


def cjoin(iterable):
    return ", ".join(iterable)


def select_all(filters, iterable):
    return (v for v in iterable if all(f(v) for f in filters))


def group_all(groupers, iterable):
    l = list(iterable)
    for g in groupers:
        l = list(g(l))
    return l


def make_grouper(key, sampler):
    def grouper(iterable):
        for k, g in itertools.groupby(sorted(iterable, key=key), key=key):
            l = sampler(k, list(g))
            for v in l:
                yield v
    return grouper


def sample_by_priority(maxlen):
    key = attrgetter("priority")

    def sampler(unused_k, l):
        if len(l) <= maxlen:
            return l
        rem = maxlen
        sampled = []
        for _, g in itertools.groupby(sorted(l, key=key, reverse=True), key=key):
            l = list(g)
            if len(l) <= rem:
                sampled.extend(l)
                rem -= len(l)
                continue
            l = random.sample(l, k=rem)
            sampled.extend(l)
            break
        return sampled
    return sampler


def sample_by_region(regions):
    def sampler(region, l):
        if region not in regions:
            return []
        maxlen = regions[region]
        if len(l) <= maxlen:
            return l
        psampler = sample_by_priority(maxlen)
        return psampler(None, l)
    return sampler


def find_configuration(src_dir):
    for name in os.listdir(src_dir):
        src_path = os.path.join(src_dir, name)
        if not os.path.isfile(src_path):
            continue
        c = Configuration.match(src_path)
        if not c:
            continue
        yield c


class Args:

    def __init__(self, args):
        self._args = args

    def __getattr__(self, name):
        return getattr(self._args, name)

    @classmethod
    def parse(cls, argv=None):
        if argv is None:
            argv = sys.argv

        parser = argparse.ArgumentParser(
            formatter_class=cls._ArgparseFormatter,
            description=__doc__)
        parser.add_argument(
            "src-dir",
            help="Directory from which upstream Mullvad .conf files are read.")
        parser.add_argument(
            "dst-dir",
            help="Directory to which output is written.  Without -f, it is an "
            "error if the directory exists.")
        parser.add_argument("-v", "--verbose", action="store_true")
        parser.add_argument("--dry-run", action="store_true", help=argparse.SUPPRESS)
        parser.add_argument(
            "-f", "--force", action="store_true",
            help="Proceed even if dst-dir is found to exist.  Any existing "
            "files in the destination directory are merged with new output.")
        parser.add_argument(
            "-n", type=int, default=10,
            help="Maximum number of configuration files written to dst-dir.  "
            "This limit is imposed last, after all --select-* filters.  "
            "Specify a non-positive value to disable this limit.")
        parser.add_argument(
            "--seed", type=int, default=0,
            help="Deterministic seed for the PRNG.  By default, every "
            "invocation produces a unique sample.")
        region_group = parser.add_mutually_exclusive_group()
        region_group.add_argument(
            "--select-region", dest="select_regions", type=cls._region_count,
            action="append", default=[], metavar="REGION-COUNT",
            help="Select servers from a specific region.  Implicitly excludes "
            "all other servers.  May be supplied more than once:  a server is "
            "selected if its region matches any REGION.  REGION-COUNT must be "
            "of form RR:N where RR is a Mullvad region code -- usually an ISO "
            "3166-1 alpha-2 code -- and N is a positive integer that specifies "
            "the maximum number of servers to select from that region.  "
            "e.g.: us:3")
        region_group.add_argument(
            "--reject-region", dest="reject_regions", type=cls._region,
            action="append", default=[], metavar="REGION",
            help="Reject all servers from a specific region.  May be supplied "
            "more than once.")
        parser.add_argument(
            "--prefer-server", dest="prefer_servers", type=cls._server_id,
            action="append", default=[], metavar="SERVERID",
            help="Assign a higher priority to a server when sampling.  Targets "
            "are more likely to be selected.  May be supplied more than once.  "
            "SERVERID must be of form RRNN, where RR is a Mullvad region code "
            "and NN is an ordinal instance index.  Leading zeroes in NN are "
            "permitted but are not significant.  e.g.: us080")
        parser.add_argument(
            "--shun-server", dest="shun_servers", type=cls._server_id,
            action="append", default=[], metavar="SERVERID",
            help="Assign a lower priority to a server when sampling.  Targets "
            "are less likely to be selected.  May be supplied more than once.")
        parser.add_argument(
            "--basename-prefix", default=DEFAULT_BASENAME_PREFIX,
            metavar="PREFIX",
            help="Common prefix for all generated file names.")
        parser.add_argument(
            "--rename", dest="renames", type=cls._server_id_name,
            action="append", default=[], metavar="SERVERID-NAME",
            help="Rename the configuration file for a given SERVERID.  May be "
            "supplied more than once, each flag with a different SERVERID.  "
            "SERVERID-NAME must be of form RRNN:NAME where RRNN is as "
            "described above, and NAME is the desired file name.  NAME may be "
            "composed of any alpha-numeric character, the hyphen (-), or the "
            "underscore (_).  PREFIX is implicitly prepended (and '.conf' "
            "implicitly appended) to form the complete name of the generated "
            "file.  e.g.: au01:au001-syd-intergrid")
        parser.add_argument(
            "--cfg-dns", metavar="DNSADDR",
            help="Override Interface.DNS from the source WireGuard "
            "configuration with an alternative constant value.  Value should "
            "be a comma separated list of IP addresses.")
        parser.add_argument(
            "--cfg-private-key", metavar="PRIVATEKEY",
            help="Override Interface.PrivateKey from the source WireGuard "
            "configuration with an alternative constant value.  Value should "
            "be a base64 encoded WireGuard private key.")
        args = parser.parse_args(argv[1:])

        select_regions_dupes = find_dupes([rc.region for rc in args.select_regions])
        if select_regions_dupes:
            parser.error(
                "--select-regions: duplicate regions: {}"
                .format(cjoin(sorted(select_regions_dupes))))

        prefer_shun_conflicts = set(args.prefer_servers) & set(args.shun_servers)
        if prefer_shun_conflicts:
            parser.error(
                "server IDs cannot be preferred and shunned simultaneously: {}"
                .format(cjoin(sorted(str(sid) for sid in prefer_shun_conflicts))))

        renames_dupes = find_dupes([sidn.sid for sidn in args.renames])
        if renames_dupes:
            parser.error(
                "--rename: duplicate server IDs: {}"
                .format(cjoin(str(sid) for sid in sorted(renames_dupes))))

        return cls(args)

    @classmethod
    def _region(cls, s):
        return cls._parse_as_type(Region, s)

    @classmethod
    def _region_count(cls, s):
        return cls._parse_as_type(RegionCount, s)

    @classmethod
    def _server_id(cls, s):
        return cls._parse_as_type(ServerID, s)

    @classmethod
    def _server_id_name(cls, s):
        return cls._parse_as_type(ServerIDName, s)

    @staticmethod
    def _parse_as_type(t, s):
        try:
            return t.parse(s)
        except (TypeError, ValueError) as exc:
            raise argparse.ArgumentTypeError(str(exc))

    class _ArgparseFormatter(argparse.RawDescriptionHelpFormatter,
                             argparse.ArgumentDefaultsHelpFormatter):
        pass


def main(argv=None):

    # pylint: disable=too-many-branches
    # pylint: disable=too-many-locals

    args = Args.parse(argv)

    if args.verbose or args.dry_run:
        logging.getLogger().setLevel(logging.INFO)
    random.seed(args.seed if args.seed else None)

    filters    = []  # AND chain over ServerIDPrioritised values
    groupers   = []  #           over ServerIDPrioritised values
    transforms = {}  # sid -> transform, else TRANSFORMS.default

    @lru_cache(maxsize=None)
    def transform(cfg):
        try:
            t = transforms[cfg.sid]
        except KeyError:
            t = TRANSFORMS.default()
        return t(cfg)

    if args.select_regions:
        select_regions = {sr.region for sr in args.select_regions}
        filters.append(lambda psid: psid.region in select_regions)
        groupers.append(make_grouper(
            lambda psid: psid.region,
            sample_by_region({sr.region: sr.count for sr in args.select_regions})))
    elif args.reject_regions:
        reject_regions = set(args.reject_regions)
        filters.append(lambda psid: psid.region not in reject_regions)
    if args.n > 0:
        groupers.append(make_grouper(
            lambda psid: 0,  # no-op sort/group key
            sample_by_priority(args.n)))
    TRANSFORMS.basename_prefix = args.basename_prefix
    if args.cfg_dns:
        TRANSFORMS.dns_servers = args.cfg_dns
    if args.cfg_private_key:
        TRANSFORMS.private_key = args.cfg_private_key
    for rename in args.renames:
        transforms[rename.sid] = TRANSFORMS.rename(rename.name)

    prioc = PriorityCache()
    for sid in args.shun_servers:
        prioc.shun_server_id(sid)
    for sid in args.prefer_servers:
        prioc.prefer_server_id(sid)

    cfgs = {cfg.sid: cfg for cfg in find_configuration(getattr(args, "src-dir"))}

    psids = compose([ServerIDPrioritised(sid=sid, priority=prioc.lookup(sid))
                     for sid in cfgs.keys()],
                    partial(select_all, filters),
                    partial(group_all, groupers),
                    sorted)

    paths = []  # of (ServerID, path) tuples
    for psid in psids:
        path, _ = transform(cfgs[psid.sid])
        paths.append((psid.sid, path))
        LOGGER.info("emit %05s prio=%d -> %s",
                    str(psid), psid.priority,
                    os.path.join(getattr(args, "dst-dir"), path))

    # Each input ServerID should map to a unique output path.
    # Improper use of the --rename flag can violate this invariant.
    path_dupes = find_dupes(p for _, p in paths)
    if path_dupes:
        raise Error("would have clobbered destination paths: {} "
                    "(improper --rename?)"
                    .format(cjoin(sorted(path_dupes))))

    if args.dry_run:
        return

    try:
        os.mkdir(getattr(args, "dst-dir"))
    except FileExistsError:
        if not args.force:
            raise Error("refused to clobber existing destination directory: {} "
                        "(supply -f/--force to disregard)"
                        .format(getattr(args, "dst-dir"))) from None
    for psid in psids:
        basename, data = transform(cfgs[psid.sid])
        path = os.path.join(getattr(args, "dst-dir"), basename)
        with open(path, "w") as f:
            data.write(f)


if __name__ == "__main__":
    logging.basicConfig(format="%(message)s", level=logging.WARNING)
    try:
        sys.exit(main(sys.argv))
    except Error as ep_exc:
        print(ep_exc, file=sys.stderr)
        sys.exit(1)
